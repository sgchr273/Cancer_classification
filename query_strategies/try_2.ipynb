{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/home/sgchr/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import torchvision\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_handler(name):\n",
    "    if name == 'MNIST':\n",
    "        return DataHandler3\n",
    "    elif name == 'FashionMNIST':\n",
    "        return DataHandler3\n",
    "    elif name == 'BreaKHis':\n",
    "        return DataHandler3\n",
    "\n",
    "\n",
    "class DataHandler3(Dataset):\n",
    "    def __init__(self, X, Y,transform = None):  #last argument is transform= None\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.X[index], self.Y[index]\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "            x = x.permute(1, 0, 2)\n",
    "        return x, y, index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "handler = get_handler('BreaKHis')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "original_tensor = torch.randn(32, 3, 32)\n",
    "\n",
    "# Permute dimensions to get the desired shape (3, 32, 32)\n",
    "desired_shape_tensor = original_tensor.permute(1, 2, 0)\n",
    "\n",
    "# Display the shape of the resulting tensor\n",
    "print(desired_shape_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=torchvision.datasets.ImageFolder('/usr/local/home/sgchr/Documents/Cancer_classification/BreaKHis_v1/Cancer_train',transform=transforms.Compose([transforms.ToTensor(),transforms.RandomResizedCrop(32), transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip()]))\n",
    "test_dataset=torchvision.datasets.ImageFolder('/usr/local/home/sgchr/Documents/Cancer_classification/BreaKHis_v1/Cancer_test',transform=transforms.Compose([transforms.ToTensor(),transforms.RandomResizedCrop(32)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_X_tr = train_dataset.imgs\n",
    "cancer_Y_tr = train_dataset.targets\n",
    "# cancer_X_te = test_dataset.data\n",
    "cancer_Y_te = test_dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('/usr/local/home/sgchr/Documents/Cancer_classification/BreaKHis_v1/Cancer_train/benign/image4407.png', 0), ('/usr/local/home/sgchr/Documents/Cancer_classification/BreaKHis_v1/Cancer_train/benign/image4408.png', 0), ('/usr/local/home/sgchr/Documents/Cancer_classification/BreaKHis_v1/Cancer_train/benign/image4409.png', 0)]\n"
     ]
    }
   ],
   "source": [
    "print(cancer_X_tr[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/CIFAR10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:15<00:00, 10722821.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/CIFAR10/cifar-10-python.tar.gz to ../data/CIFAR10\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_tr = torchvision.datasets.CIFAR10('../data' + '/CIFAR10', train=True, download=True)\n",
    "data_te = torchvision.datasets.CIFAR10('../data' + '/CIFAR10', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR_X_tr = data_tr.data\n",
    "CIFAR_Y_tr = data_tr.targets\n",
    "CIFAR_X_te = data_te.data\n",
    "CIFAR_Y_te = data_te.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    " \n",
    "\n",
    "    loader_tr = DataLoader(train_dataset, batch_size=1000)\n",
    "    loader_te = DataLoader(test_dataset, batch_size=1000)\n",
    "    X_tr, Y_tr, X_te, Y_te = [],[],[],[]\n",
    "    for (x,y) in loader_tr:\n",
    "        X_tr.append(x), Y_tr.append(y)\n",
    "\n",
    "    X_tr = torch.cat(X_tr, dim=0)\n",
    "    X_tr = X_tr.permute(0, 2, 3, 1)\n",
    "    X_tr = X_tr.numpy()\n",
    "\n",
    "    Y_tr = torch.cat(Y_tr, dim=0)\n",
    "\n",
    "    # X_tr , Y_tr= np.array(X_tr), np.array(Y_tr)\n",
    "\n",
    "    for (x,y) in loader_te:\n",
    "        X_te.append(x), Y_te.append(y)\n",
    "\n",
    "    X_te = torch.cat(X_te, dim=0)\n",
    "    X_te = X_te.permute(0, 2, 3, 1)\n",
    "    X_te = X_te.numpy()\n",
    "\n",
    "    Y_te = torch.cat(Y_te, dim=0)\n",
    "\n",
    "    return X_tr, X_te, Y_tr, Y_te\n",
    "X_tr, X_te, Y_tr, Y_te = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have your dataset (X, Y) and a transform function (transform_fn)\n",
    "test_data = DataHandler3(X_te, Y_te)\n",
    "train_data = DataHandler3(X_tr, Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Label: 0\n"
     ]
    }
   ],
   "source": [
    "for x, y, idx in test_data:\n",
    "    # Process or use x, y, idx as needed\n",
    "    print(f\"Index: {idx}, Label: {y}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Label: 0\n"
     ]
    }
   ],
   "source": [
    "for x_train, y_train, idx in train_data:\n",
    "    # Process or use x, y, idx as needed\n",
    "    print(f\"Index: {idx}, Label: {y}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'n_epoch': 20, 'transform':transforms.Compose([\n",
    "                    transforms.RandomRotation(20),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.RandomVerticalFlip(),\n",
    "                    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "                    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), shear=(0.2, 0.2)),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet mean and std\n",
    "                ]),\n",
    "                'loader_tr_args':{'batch_size': 64, 'num_workers': 1},\n",
    "                'loader_te_args':{'batch_size': 64, 'num_workers': 1},\n",
    "                'optimizer_args':{'lr': 0.00001, 'momentum': 0.5},\n",
    "                'transformTest' : transforms.Compose([transforms.ToTensor(),\n",
    "         transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_tr = DataLoader(handler(X_tr, torch.Tensor(Y_tr.numpy()).long(), transform = args['transform']), shuffle=True, **args['loader_tr_args'])\n",
    "loader_te = DataLoader(handler(X_te, torch.Tensor(Y_te.numpy()).long(), transform = args['transform']), shuffle=True, **args['loader_te_args'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (x, y, idxs) in enumerate(loader_tr):\n",
    "    print(x.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (x_te, y_te, idxs) in enumerate(loader_te):\n",
    "    print(x_te.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Index: 0\n",
      "Images Shape: torch.Size([1000, 3, 32, 32])\n",
      "Labels Shape: torch.Size([1000])\n",
      "Batch Index: 1\n",
      "Images Shape: torch.Size([1000, 3, 32, 32])\n",
      "Labels Shape: torch.Size([1000])\n",
      "Batch Index: 2\n",
      "Images Shape: torch.Size([1000, 3, 32, 32])\n",
      "Labels Shape: torch.Size([1000])\n",
      "Batch Index: 3\n",
      "Images Shape: torch.Size([1000, 3, 32, 32])\n",
      "Labels Shape: torch.Size([1000])\n",
      "Batch Index: 4\n",
      "Images Shape: torch.Size([1000, 3, 32, 32])\n",
      "Labels Shape: torch.Size([1000])\n",
      "Batch Index: 5\n",
      "Images Shape: torch.Size([1000, 3, 32, 32])\n",
      "Labels Shape: torch.Size([1000])\n",
      "Batch Index: 6\n",
      "Images Shape: torch.Size([1000, 3, 32, 32])\n",
      "Labels Shape: torch.Size([1000])\n",
      "Batch Index: 7\n",
      "Images Shape: torch.Size([1000, 3, 32, 32])\n",
      "Labels Shape: torch.Size([1000])\n",
      "Batch Index: 8\n",
      "Images Shape: torch.Size([812, 3, 32, 32])\n",
      "Labels Shape: torch.Size([812])\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for batch_idx, (images, labels) in enumerate(loader_tr):\n",
    "    # 'images' is a tensor containing the images in the batch\n",
    "    # 'labels' is a tensor containing the corresponding labels\n",
    "    count+=1\n",
    "    # Your training loop or processing here\n",
    "    print('Batch Index:', batch_idx)\n",
    "    print('Images Shape:', images.shape)\n",
    "    print('Labels Shape:', labels.shape)\n",
    "    if count == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 1, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = torch.cat(X_tr, dim=0)\n",
    "X_tr = X_tr.numpy()\n",
    "Y_tr = torch.cat(Y_tr, dim=0)\n",
    "# X_tr , Y_tr= np.array(X_tr), np.array(Y_tr)\n",
    "\n",
    "X_te = torch.cat(X_te, dim=0)\n",
    "X_te = X_te.numpy()\n",
    "Y_te = torch.cat(Y_te, dim=0)\n",
    "# X_te , Y_te= np.array(X_te), np.array(Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class CancerModel(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(CancerModel, self).__init__()\n",
    "        self.in_planes = 16\n",
    "        self.embDim = 128 * block.expansion\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 128, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(128 * block.expansion, num_classes, bias=False)\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        emb = out.view(out.size(0), -1)\n",
    "        out = self.linear(emb)\n",
    "        return out, emb\n",
    "    def get_embedding_dim(self):\n",
    "        return self.embDim    \n",
    "\n",
    "def Cancer(num_classes=2):\n",
    "    return CancerModel(BasicBlock, [2,2,2,2], num_classes)\n",
    "\n",
    "net = Cancer(num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = get_handler('BreaKHis')\n",
    "train_loader = DataLoader(handler(X_train, Y_train, transform=args['BreaKHis']['transform']), shuffle=False, **args['BreaKHis']['loader_te_args'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(handler(train_dataset, test_dataset, transform=args['BreaKHis']['transform']), shuffle=False, **args['BreaKHis']['loader_te_args'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = torch.zeros(len(loader_tr.dataset)).long()\n",
    "\n",
    "for batch_idx, (images, labels) in enumerate(loader_tr):\n",
    "    batch_size = len(labels)\n",
    "    indices = batch_idx * loader_tr.batch_size + torch.arange(batch_size)\n",
    "    out, e1 = net(images)\n",
    "    _, preds = torch.max(out, 1)\n",
    "    pred = out.max(1)[1]\n",
    "    P[indices] = pred.data.cpu()\n",
    "\n",
    "accur = 1.0 * (labels == P[:len(labels)]).sum().item() / len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = torch.zeros(len(loader_tr.dataset)).long()\n",
    "all_labels = torch.zeros(len(loader_tr.dataset)).long()\n",
    "\n",
    "for batch_idx, (images, labels) in enumerate(loader_tr):\n",
    "    batch_size = len(labels)\n",
    "    indices = batch_idx * loader_tr.batch_size + torch.arange(batch_size)\n",
    "    out, e1 = net(images)\n",
    "    _, preds = torch.max(out, 1)\n",
    "    pred = out.max(1)[1]\n",
    "    P[indices] = pred.data.cpu()\n",
    "    all_labels[indices] = labels\n",
    "\n",
    "accur = 1.0 * (all_labels == P).sum().item() / len(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "for (x,y) in loader_tr:\n",
    "    print(x.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_tr[6].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(X_tr[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cancer_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
